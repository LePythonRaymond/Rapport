import re
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional, Tuple
from dateutil import parser
import pytz
import config
from src.google_chat.people_resolver import format_name

def extract_date_from_message(message: Dict[str, Any]) -> Optional[datetime]:
    """
    Parse timestamp from Google Chat message.

    Args:
        message: Message dictionary with 'createTime' field

    Returns:
        Parsed datetime object or None if parsing fails
    """
    try:
        create_time = message.get('createTime', '')
        if not create_time:
            return None

        # Parse ISO format timestamp
        parsed_date = parser.parse(create_time)
        return parsed_date
    except Exception as e:
        print(f"Error parsing date from message: {e}")
        return None

def filter_messages_by_date(messages: List[Dict[str, Any]], start_date: datetime, end_date: datetime) -> List[Dict[str, Any]]:
    """
    Filter messages within the specified date range.

    Args:
        messages: List of message dictionaries
        start_date: Start date for filtering
        end_date: End date for filtering

    Returns:
        Filtered list of messages within date range
    """
    filtered_messages = []

    for message in messages:
        message_date = extract_date_from_message(message)
        if message_date is None:
            continue

        # Ensure timezone awareness
        if start_date.tzinfo is None:
            start_date = start_date.replace(tzinfo=timezone.utc)
        if end_date.tzinfo is None:
            end_date = end_date.replace(tzinfo=timezone.utc)

        if start_date <= message_date <= end_date:
            filtered_messages.append(message)

    return filtered_messages

def extract_images_from_message(message: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Extract attachment information from a message.

    Args:
        message: Message dictionary with attachments

    Returns:
        List of attachment dictionaries with download info
    """
    images = []
    attachments = message.get('attachments', [])

    # Debug logging
    if attachments:
        print(f"ðŸ“Ž Found {len(attachments)} attachments in message")

    for attachment in attachments:
        # Check if it's an image
        content_type = attachment.get('contentType', '').lower()
        if content_type.startswith('image/'):
            image_info = {
                'name': attachment.get('name', ''),
                'contentType': content_type,
                'downloadUri': attachment.get('downloadUri', ''),  # Fixed: use correct key
                'size': attachment.get('attachmentDataRef', {}).get('size', 0),
                'attachmentDataRef': attachment.get('attachmentDataRef', {})  # Preserve for download
            }
            images.append(image_info)
            print(f"ðŸ–¼ï¸ Extracted image: {image_info['name']} ({content_type})")

    return images

def split_message_text_at_off(text: str) -> Tuple[str, bool]:
    """
    Split message text at (OFF) marker and return text before it.

    Args:
        text: Message text that may contain (OFF) marker

    Returns:
        Tuple of (text_before_off, has_off_marker)
    """
    if not text:
        return "", False

    # Case-insensitive search for OFF marker
    pattern = re.compile(config.OFF_MARKERS_PATTERN, re.IGNORECASE)
    match = pattern.search(text)

    if match:
        # Return text before OFF marker
        text_before = text[:match.start()].strip()
        return text_before, True

    return text, False

def apply_off_rule_filtering(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Apply (OFF) rule filtering to messages before grouping.

    Rules:
    - If (OFF) is first message of the day for an author: exclude all messages from that author for that day
    - If (OFF) is in middle of message: split text at (OFF), keep only before part
    - If (OFF) is in separate message: exclude that message and all subsequent messages from that author on that day

    Args:
        messages: List of message dictionaries sorted by time

    Returns:
        Filtered list of messages with OFF rule applied
    """
    if not messages:
        return []

    # Get Paris timezone
    paris_tz = pytz.timezone(config.PARIS_TIMEZONE)

    # Track which (author, date) combinations should be excluded after a certain time
    off_markers = {}  # {(author_email, date): off_message_time}

    # First pass: identify OFF markers and when they occur
    for message in messages:
        message_date = extract_date_from_message(message)
        if message_date is None:
            continue

        # Convert to Paris timezone
        if message_date.tzinfo is None:
            message_date = message_date.replace(tzinfo=timezone.utc)
        message_date_paris = message_date.astimezone(paris_tz)
        date_key = message_date_paris.date()

        author_email = message.get('author', {}).get('email', '')
        if not author_email:
            continue

        text = message.get('text', '')

        # Check if message contains OFF marker
        pattern = re.compile(config.OFF_MARKERS_PATTERN, re.IGNORECASE)
        if pattern.search(text):
            key = (author_email, date_key)
            # Store the time when OFF was encountered (if not already stored or if earlier)
            if key not in off_markers or message_date_paris < off_markers[key]:
                off_markers[key] = message_date_paris
                print(f"ðŸš« OFF marker detected for {author_email} on {date_key} at {message_date_paris.strftime('%H:%M')}")

    # Second pass: filter messages and split text where needed
    filtered_messages = []

    for message in messages:
        message_date = extract_date_from_message(message)
        if message_date is None:
            # Keep messages without dates (shouldn't happen but be safe)
            filtered_messages.append(message)
            continue

        # Convert to Paris timezone
        if message_date.tzinfo is None:
            message_date = message_date.replace(tzinfo=timezone.utc)
        message_date_paris = message_date.astimezone(paris_tz)
        date_key = message_date_paris.date()

        author_email = message.get('author', {}).get('email', '')
        if not author_email:
            filtered_messages.append(message)
            continue

        key = (author_email, date_key)

        # Check if this author+day has an OFF marker
        if key in off_markers:
            off_time = off_markers[key]

            # If message is before OFF time, include it (possibly with split text)
            if message_date_paris < off_time:
                filtered_messages.append(message)
            elif message_date_paris == off_time:
                # This is the message with OFF marker - split the text
                text = message.get('text', '')
                text_before_off, has_off = split_message_text_at_off(text)

                if text_before_off.strip():
                    # Create a copy of the message with split text
                    filtered_message = message.copy()
                    filtered_message['text'] = text_before_off
                    filtered_messages.append(filtered_message)
                    print(f"âœ‚ï¸ Split message at OFF for {author_email}: kept '{text_before_off[:50]}...'")
                else:
                    print(f"ðŸš« Excluded message starting with OFF for {author_email}")
            else:
                # Message is after OFF time - exclude it
                print(f"ðŸš« Excluded message after OFF for {author_email} on {date_key}")
        else:
            # No OFF marker for this author+day - keep message as is
            filtered_messages.append(message)

    print(f"ðŸ“Š OFF rule filtering: {len(messages)} messages â†’ {len(filtered_messages)} messages")
    return filtered_messages

def extract_date_from_text(text: str) -> Tuple[Optional[int], Optional[int], bool]:
    """
    Extract date in DD/MM format from text.

    Args:
        text: Message text that may contain date

    Returns:
        Tuple of (day, month, found_date)
        If no date found: (None, None, False)
    """
    if not text:
        return None, None, False

    # Search for DD/MM pattern
    pattern = re.compile(config.DATE_PATTERN)
    match = pattern.search(text)

    if match:
        try:
            day = int(match.group(1))
            month = int(match.group(2))

            # Validate day and month ranges
            if 1 <= day <= 31 and 1 <= month <= 12:
                print(f"ðŸ“… Extracted date from text: {day:02d}/{month:02d}")
                return day, month, True
            else:
                print(f"âš ï¸ Invalid date values in text: {day}/{month}")
                return None, None, False
        except (ValueError, IndexError):
            return None, None, False

    return None, None, False

def detect_avant_apres_sections(messages_in_intervention: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Detect AVANT/APRÃˆS sections in intervention messages and categorize images.
    Only treats "avant/aprÃ¨s" as markers when they appear as standalone section markers,
    not when used in regular sentences.

    Args:
        messages_in_intervention: List of messages belonging to one intervention

    Returns:
        Dictionary with categorized images and text:
        {
            'has_avant_apres': bool,
            'avant_images': [...],
            'apres_images': [...],
            'regular_images': [...],
            'regular_text': str
        }
    """
    result = {
        'has_avant_apres': False,
        'avant_images': [],
        'apres_images': [],
        'regular_images': [],
        'regular_text': ''
    }

    if not messages_in_intervention:
        return result

    # Track state: 'before_avant', 'in_avant', 'in_apres'
    state = 'before_avant'
    text_parts = []

    def is_marker_message(text: str, marker_pattern: re.Pattern) -> bool:
        """
        Check if text is a section marker (not just containing the word in regular text).
        A marker message is one where the marker word appears with minimal other content.
        """
        if not text:
            return False

        # Clean up the text
        text_clean = text.strip().lower()

        # Check if the entire message is just the marker (possibly with punctuation)
        # e.g., "Avant", "avant", "AVANT", "Avant:", "Avant !", etc.
        if re.match(r'^(avant|aprÃ¨s|apres)\s*[:\-!.]*$', text_clean):
            return True

        # Check if text is very short (< 15 chars) and contains the marker
        # This catches cases like "Avant" or "Avant photo"
        if len(text_clean) < 15 and marker_pattern.search(text):
            return True

        return False

    avant_pattern = re.compile(config.AVANT_MARKERS_PATTERN, re.IGNORECASE)
    apres_pattern = re.compile(config.APRES_MARKERS_PATTERN, re.IGNORECASE)

    for message in messages_in_intervention:
        text = message.get('text', '')
        images = message.get('attachments', [])

        # Check if this message is an AVANT or APRÃˆS marker (not just containing the word)
        is_avant_marker = is_marker_message(text, avant_pattern)
        is_apres_marker = is_marker_message(text, apres_pattern)

        # Update state based on markers
        if is_avant_marker and state == 'before_avant':
            state = 'in_avant'
            result['has_avant_apres'] = True
            print(f"ðŸ–¼ï¸ AVANT section detected (marker text: '{text.strip()}')")
        elif is_apres_marker and state in ['before_avant', 'in_avant']:
            state = 'in_apres'
            result['has_avant_apres'] = True
            print(f"ðŸ–¼ï¸ APRÃˆS section detected (marker text: '{text.strip()}')")

        # Categorize images based on current state
        for attachment in images:
            content_type = attachment.get('contentType', '').lower()
            if content_type.startswith('image/'):
                if state == 'before_avant':
                    result['regular_images'].append(attachment)
                elif state == 'in_avant':
                    result['avant_images'].append(attachment)
                elif state == 'in_apres':
                    result['apres_images'].append(attachment)

        # Collect text for regular_text
        # Only exclude text if it's a pure marker message
        if text and not (is_avant_marker or is_apres_marker):
            text_parts.append(text)
        # If it's a marker with some additional text, include the non-marker part
        # (though typically markers should be standalone)

    result['regular_text'] = '\n'.join(text_parts)

    if result['has_avant_apres']:
        print(f"ðŸ“Š AVANT/APRÃˆS detection: {len(result['avant_images'])} avant, {len(result['apres_images'])} aprÃ¨s, {len(result['regular_images'])} regular images")

    return result

def group_messages_by_intervention(messages: List[Dict[str, Any]], time_threshold_minutes: int = None) -> List[Dict[str, Any]]:
    """
    Group related messages (text + images) as single interventions.
    Messages from the same author on the same day (Paris timezone) are grouped together.
    Messages from office team members are excluded.

    Args:
        messages: List of message dictionaries
        time_threshold_minutes: Deprecated parameter, kept for backward compatibility but ignored

    Returns:
        List of intervention dictionaries, each containing grouped messages
    """
    if not messages:
        return []

    # Get Paris timezone
    paris_tz = pytz.timezone(config.PARIS_TIMEZONE)

    # Filter out office team members' messages
    office_team_members = [name.lower() for name in config.OFFICE_TEAM_MEMBERS]
    filtered_messages = []

    for message in messages:
        author_name = message.get('author', {}).get('name', '')
        author_name_lower = author_name.lower()

        # Check if author is office team member
        is_office_team = any(
            office_name.lower() == author_name_lower
            for office_name in config.OFFICE_TEAM_MEMBERS
        )

        if is_office_team:
            print(f"ðŸš« Excluding intervention from office team member: {author_name}")
            continue

        filtered_messages.append(message)

    if not filtered_messages:
        return []

    # Sort messages by time
    sorted_messages = sorted(filtered_messages, key=lambda x: extract_date_from_message(x) or datetime.min.replace(tzinfo=timezone.utc))

    interventions = []
    current_intervention = None

    for message in sorted_messages:
        message_date = extract_date_from_message(message)
        if message_date is None:
            continue

        # Convert to Paris timezone
        if message_date.tzinfo is None:
            message_date = message_date.replace(tzinfo=timezone.utc)
        message_date_paris = message_date.astimezone(paris_tz)
        message_day = message_date_paris.date()

        author_email = message.get('author', {}).get('email', '')
        text = message.get('text', '').strip()

        # Don't skip messages with only images - they should be included
        # (This was already handled correctly, but making it explicit)

        # Check if this message should start a new intervention
        # New intervention if: no current intervention, different author, or different day
        should_start_new = (
            current_intervention is None or
            author_email != current_intervention['author_email'] or
            message_day != current_intervention['intervention_day']
        )

        if should_start_new:
            # Save previous intervention if it exists
            if current_intervention is not None:
                # Process avant/aprÃ¨s sections and extract date before saving
                _finalize_intervention(current_intervention)
                interventions.append(current_intervention)

            # Before creating a new intervention, check if there's already
            # a finalized intervention for this author on this day
            existing_intervention = None
            for intervention in interventions:
                if (intervention.get('author_email') == author_email and
                    intervention.get('intervention_day') == message_day):
                    existing_intervention = intervention
                    break

            if existing_intervention is not None:
                # Merge message into existing intervention
                # Insert message in chronological order within the messages list
                existing_messages = existing_intervention['messages']
                insert_position = len(existing_messages)
                for i, existing_msg in enumerate(existing_messages):
                    existing_msg_date = extract_date_from_message(existing_msg)
                    if existing_msg_date and message_date < existing_msg_date:
                        insert_position = i
                        break
                existing_messages.insert(insert_position, message)

                # Append text to all_text with newline separator
                if text:
                    if existing_intervention.get('all_text'):
                        existing_intervention['all_text'] += f"\n{text}"
                    else:
                        existing_intervention['all_text'] = text

                # Update last_message_time if this message is later
                if message_date > existing_intervention.get('last_message_time', datetime.min.replace(tzinfo=timezone.utc)):
                    existing_intervention['last_message_time'] = message_date

                # Update start_time if this message is earlier
                if message_date < existing_intervention.get('start_time', datetime.max.replace(tzinfo=timezone.utc)):
                    existing_intervention['start_time'] = message_date

                # Extend images list with new images
                existing_intervention['images'].extend(extract_images_from_message(message))

                # Re-finalize intervention to update metadata (date extraction, avant/aprÃ¨s detection)
                _finalize_intervention(existing_intervention)

                # Don't create a new intervention, continue to next message
                current_intervention = None
                continue

            # Start new intervention (no existing intervention found)
            current_intervention = {
                'author_email': author_email,
                'author_name': message.get('author', {}).get('name', 'Unknown'),
                'start_time': message_date,
                'intervention_day': message_day,
                'last_message_time': message_date,
                'messages': [message],
                'all_text': text if text else '',
                'images': extract_images_from_message(message)
            }
        else:
            # Add to current intervention
            current_intervention['messages'].append(message)
            if text:
                if current_intervention['all_text']:
                    current_intervention['all_text'] += f"\n{text}"
                else:
                    current_intervention['all_text'] = text
            current_intervention['last_message_time'] = message_date

            # Add images from this message
            current_intervention['images'].extend(extract_images_from_message(message))

    # Add the last intervention
    if current_intervention is not None:
        _finalize_intervention(current_intervention)
        interventions.append(current_intervention)

    # Debug logging
    total_images = sum(len(intervention.get('images', [])) for intervention in interventions)
    print(f"ðŸ“Š Grouped {len(messages)} messages into {len(interventions)} interventions with {total_images} total images")

    # Log author names found in interventions
    author_names_found = set()
    for intervention in interventions:
        author_name = intervention.get('author_name', 'Unknown')
        if author_name:
            author_names_found.add(author_name)
    print(f"ðŸ‘¤ Author names found in interventions: {sorted(list(author_names_found))}")

    return interventions

def _finalize_intervention(intervention: Dict[str, Any]) -> None:
    """
    Finalize an intervention by extracting date from text and detecting avant/aprÃ¨s sections.

    Args:
        intervention: Intervention dictionary to finalize (modified in place)
    """
    # Extract date from text
    all_text = intervention.get('all_text', '')
    day, month, found_date = extract_date_from_text(all_text)

    if found_date and day and month:
        # Use current year (or year from start_time if available)
        start_time = intervention.get('start_time')
        year = start_time.year if start_time else datetime.now().year

        try:
            intervention_date = datetime(year, month, day)
            intervention['intervention_date'] = intervention_date
            intervention['date_source'] = 'extracted'
        except ValueError:
            # Invalid date - fall back to timestamp
            intervention['intervention_date'] = intervention.get('start_time')
            intervention['date_source'] = 'timestamp'
    else:
        # No date found in text - use timestamp
        intervention['intervention_date'] = intervention.get('start_time')
        intervention['date_source'] = 'timestamp'

    # Detect avant/aprÃ¨s sections
    messages_list = intervention.get('messages', [])
    avant_apres_data = detect_avant_apres_sections(messages_list)

    # Add avant/aprÃ¨s data to intervention
    intervention['has_avant_apres'] = avant_apres_data['has_avant_apres']
    intervention['avant_images'] = avant_apres_data['avant_images']
    intervention['apres_images'] = avant_apres_data['apres_images']
    intervention['regular_images'] = avant_apres_data['regular_images']

    # If there's specific text from avant/aprÃ¨s parsing, use it
    if avant_apres_data['regular_text']:
        intervention['all_text'] = avant_apres_data['regular_text']

def _time_gap_too_large(current_time: datetime, last_time: datetime, threshold_minutes: int) -> bool:
    """
    Check if the time gap between two messages is too large to group them.

    Args:
        current_time: Current message timestamp
        last_time: Last message timestamp
        threshold_minutes: Maximum gap in minutes

    Returns:
        True if gap is too large, False otherwise
    """
    time_diff = current_time - last_time
    return time_diff.total_seconds() > (threshold_minutes * 60)

def extract_mentions_from_text(text: str) -> List[str]:
    """
    Extract @mentions from message text.

    Handles formats like:
    - @Alice MARTIN
    - @ALICE MARTIN
    - @Jean-Pierre DUPONT
    - @Marie Louise BERNARD

    Args:
        text: Message text that may contain @mentions

    Returns:
        List of mentioned names (without @ symbol)
    """
    if not text:
        return []

    # Pattern to match @Name Name (2+ words, stopping at lowercase words or punctuation)
    # Matches names in any case (UPPERCASE, lowercase, Mixed)
    # Stops at common lowercase conjunctions (et, a, ont, etc.) or non-letter characters
    # Each name part must start with a letter and can contain letters and hyphens
    mention_pattern = r'@([A-ZÃ€-Å¸][A-ZÃ€-Å¸a-zÃ -Ã¿\-]+(?:[ \t]+[A-ZÃ€-Å¸][A-ZÃ€-Å¸a-zÃ -Ã¿\-]+)*)'

    mentions = re.findall(mention_pattern, text)

    if mentions:
        print(f"ðŸ‘¥ Found {len(mentions)} mention(s) in text: {mentions}")

    return mentions

def extract_team_members(messages: List[Dict[str, Any]]) -> List[Dict[str, str]]:
    """
    Extract unique team members from messages, including authors and @mentioned people.
    Excludes office team members.

    Args:
        messages: List of message dictionaries

    Returns:
        List of team member dictionaries with name and email (excluding office team)
    """
    team_members = {}
    office_team_members = [name.lower() for name in config.OFFICE_TEAM_MEMBERS]  # Case-insensitive comparison

    for message in messages:
        # Extract message author
        author = message.get('author', {})
        email = author.get('email', '')
        name = author.get('name', 'Unknown')

        # Skip office team members (case-insensitive check)
        name_lower = name.lower()
        is_office_team = any(office_name.lower() == name_lower for office_name in config.OFFICE_TEAM_MEMBERS)

        if not is_office_team:
            # Only add if we have an email and it's not already in the list
            if email and email not in team_members:
                formatted_name = format_name(name)
                team_members[email] = {
                    'name': formatted_name,
                    'email': email
                }
                print(f"âœ… Added team member (author): {formatted_name} ({email})")
        else:
            print(f"ðŸš« Excluded office team member from team_info: {name}")

        # Extract @mentions from message text
        text = message.get('text', '')
        if text:
            mentioned_names = extract_mentions_from_text(text)

            for mentioned_name in mentioned_names:
                # Format the name properly
                formatted_mentioned_name = format_name(mentioned_name)

                # Check if mentioned person is office team member
                mentioned_name_lower = formatted_mentioned_name.lower()
                is_mentioned_office_team = any(
                    office_name.lower() == mentioned_name_lower
                    for office_name in config.OFFICE_TEAM_MEMBERS
                )

                if is_mentioned_office_team:
                    print(f"ðŸš« Excluded mentioned office team member: {formatted_mentioned_name}")
                    continue

                # Use name as key (since we don't have email for mentioned people)
                # Use a synthetic key to avoid conflicts
                mention_key = f"mention_{formatted_mentioned_name.lower().replace(' ', '_')}"

                if mention_key not in team_members:
                    team_members[mention_key] = {
                        'name': formatted_mentioned_name,
                        'email': ''  # No email available for mentioned people
                    }
                    print(f"âœ… Added team member (mentioned): {formatted_mentioned_name}")

    return list(team_members.values())

def clean_text(text: str) -> str:
    """
    Clean and normalize text from messages.

    Args:
        text: Raw text from message

    Returns:
        Cleaned text
    """
    if not text:
        return ""

    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text)

    # Remove common chat artifacts
    text = re.sub(r'^[:\-\s]+', '', text)  # Remove leading colons, dashes
    text = re.sub(r'[:\-\s]+$', '', text)  # Remove trailing colons, dashes

    return text.strip()

def categorize_intervention_type(text: str) -> str:
    """
    Categorize intervention type based on text content.

    Args:
        text: Intervention text

    Returns:
        Category string (e.g., "Taille", "DÃ©sherbage", "Arrosage", etc.)
    """
    text_lower = text.lower()

    # Define keyword mappings
    categories = {
        'Taille': ['taille', 'taillÃ©', 'coupe', 'Ã©lagage', 'Ã©laguÃ©'],
        'DÃ©sherbage': ['dÃ©sherbage', 'dÃ©sherbÃ©', 'mauvaises herbes', 'herbes'],
        'Arrosage': ['arrosage', 'arrosÃ©', 'eau', 'irrigation'],
        'Nettoyage': ['nettoyage', 'nettoyÃ©', 'propre', 'ramassage'],
        'Plantation': ['plantation', 'plantÃ©', 'semis', 'repiquage'],
        'Fertilisation': ['engrais', 'fertilisation', 'nutriments'],
        'Palissage': ['palissage', 'palissÃ©', 'tuteur', 'support'],
        'Entretien gÃ©nÃ©ral': ['entretien', 'maintenance', 'ras', 'rien Ã  signaler']
    }

    # Find matching category
    for category, keywords in categories.items():
        for keyword in keywords:
            if keyword in text_lower:
                return category

    return 'Autre'

def extract_key_phrases(text: str) -> List[str]:
    """
    Extract key phrases from intervention text.

    Args:
        text: Intervention text

    Returns:
        List of key phrases
    """
    # Common gardening terms to look for
    key_terms = [
        'taille', 'dÃ©sherbage', 'arrosage', 'nettoyage', 'plantation',
        'fertilisation', 'palissage', 'Ã©lagage', 'coupe', 'semis',
        'repiquage', 'tuteur', 'support', 'engrais', 'irrigation'
    ]

    found_phrases = []
    text_lower = text.lower()

    for term in key_terms:
        if term in text_lower:
            found_phrases.append(term)

    return found_phrases

def validate_intervention_data(intervention: Dict[str, Any]) -> Tuple[bool, List[str]]:
    """
    Validate intervention data for completeness and quality.

    Args:
        intervention: Intervention dictionary

    Returns:
        Tuple of (is_valid, list_of_issues)
    """
    issues = []

    # Check required fields
    if not intervention.get('all_text', '').strip():
        issues.append("No text content")

    if not intervention.get('author_name'):
        issues.append("No author information")

    if not intervention.get('start_time'):
        issues.append("No timestamp")

    # Check text quality
    text = intervention.get('all_text', '')
    if len(text.strip()) < 3:
        issues.append("Text too short")

    # Check for meaningful content
    if text.lower().strip() in ['ok', 'okay', 'rien', '']:
        issues.append("Minimal content")

    is_valid = len(issues) == 0
    return is_valid, issues

def format_intervention_summary(intervention: Dict[str, Any]) -> str:
    """
    Create a summary string for an intervention.

    Args:
        intervention: Intervention dictionary

    Returns:
        Formatted summary string
    """
    author = intervention.get('author_name', 'Unknown')
    start_time = intervention.get('start_time')
    text = intervention.get('all_text', '')

    if start_time:
        time_str = start_time.strftime('%d/%m/%Y %H:%M')
    else:
        time_str = 'Unknown time'

    # Truncate text if too long
    if len(text) > 100:
        text = text[:97] + '...'

    return f"{author} - {time_str}: {text}"
